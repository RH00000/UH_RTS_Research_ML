{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDlAZmbw72/shCGeEURntu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RH00000/UH_RTS_Research_ML/blob/main/profiling_stats_for_abcd_models_for_10000_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision tensorflow-datasets"
      ],
      "metadata": {
        "id": "ivrc2earSZrh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "yv0X1RBvgi5p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Load the ImageNetV2 TopImages split via TFDS\n",
        "builder = tfds.builder(\"imagenet_v2\", config=\"topimages\")\n",
        "builder.download_and_prepare()\n",
        "tfds_ds = builder.as_dataset(split=\"test\", as_supervised=True)"
      ],
      "metadata": {
        "id": "xCSXwqnxgo_v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2: Wrap TFDS dataset in a PyTorch IterableDataset\n",
        "class ImageNetV2TopImages(IterableDataset):\n",
        "    def __init__(self, tfds_dataset, transform=None):\n",
        "        self.ds = tfds_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __iter__(self):\n",
        "        for img, label in tfds.as_numpy(self.ds):\n",
        "            pil = Image.fromarray(img)\n",
        "            if self.transform:\n",
        "                pil = self.transform(pil)\n",
        "            yield pil, label"
      ],
      "metadata": {
        "id": "ofB_1Zjagpyj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3: Define preprocessing to match ResNet expectations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "rYXxD7aOgywF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4: Instantiate DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = ImageNetV2TopImages(tfds_ds, transform=preprocess)\n",
        "loader  = DataLoader(dataset, batch_size=1, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncPv1ibtg13J",
        "outputId": "7d91de18-ca04-48d6-d468-38f02862814e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: Load pretrained ResNet models (A-D)\n",
        "resnet18  = models.resnet18(pretrained=True).to(device).eval()   # model A\n",
        "resnet34  = models.resnet34(pretrained=True).to(device).eval()   # model B\n",
        "resnet50  = models.resnet50(pretrained=True).to(device).eval()   # model C\n",
        "resnet152 = models.resnet152(pretrained=True).to(device).eval()  # model D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8eDKKQBg7Zw",
        "outputId": "7ae2f497-2ee3-42b2-e201-d1c101fc3123"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 132MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 108MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 169MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:01<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6: Profile all models on the validation set\n",
        "N = 10000  # number of images in the TopImages split\n",
        "confs = np.zeros((N, 4), dtype=np.float32)\n",
        "times = np.zeros((N, 4), dtype=np.float32)\n",
        "ok_flags = np.zeros((N, 4), dtype=bool)\n",
        "models_list = [resnet18, resnet34, resnet50, resnet152]\n",
        "\n",
        "for idx, (img, label) in enumerate(loader):\n",
        "    img = img.to(device)\n",
        "    label = label.to(device).item()\n",
        "\n",
        "    for i, model in enumerate(models_list):\n",
        "        start = time.perf_counter()\n",
        "        with torch.no_grad():\n",
        "            logits = model(img)\n",
        "            probs  = F.softmax(logits, dim=1)\n",
        "            conf, pred = torch.max(probs, dim=1)\n",
        "        elapsed = time.perf_counter() - start\n",
        "\n",
        "        confs[idx, i]    = conf.item()\n",
        "        times[idx, i]    = elapsed\n",
        "        ok_flags[idx, i] = (pred.item() == label)\n",
        "\n",
        "    if (idx + 1) % 500 == 0:\n",
        "        print(f\"Processed {idx+1}/{N} images\")\n",
        "    if idx >= N - 1:\n",
        "        break\n",
        "\n",
        "# 7: Save profiling data\n",
        "np.savez('validation_stats.npz', confs=confs, times=times, oks=ok_flags)\n",
        "print(\"Saved profiling data to 'validation_stats.npz'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCrWYcX-hE5T",
        "outputId": "cd733682-a734-4b57-d701-1e9ce151c4eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 500/10000 images\n",
            "Processed 1000/10000 images\n",
            "Processed 1500/10000 images\n",
            "Processed 2000/10000 images\n",
            "Processed 2500/10000 images\n",
            "Processed 3000/10000 images\n",
            "Processed 3500/10000 images\n",
            "Processed 4000/10000 images\n",
            "Processed 4500/10000 images\n",
            "Processed 5000/10000 images\n",
            "Processed 5500/10000 images\n",
            "Processed 6000/10000 images\n",
            "Processed 6500/10000 images\n",
            "Processed 7000/10000 images\n",
            "Processed 7500/10000 images\n",
            "Processed 8000/10000 images\n",
            "Processed 8500/10000 images\n",
            "Processed 9000/10000 images\n",
            "Processed 9500/10000 images\n",
            "Processed 10000/10000 images\n",
            "Saved profiling data to 'validation_stats.npz'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8: Preview the first 5 entries\n",
        "data = np.load('validation_stats.npz')\n",
        "confs = data['confs']; times = data['times']; oks = data['oks']\n",
        "print(\"\\nFirst 5 confidences (A,B,C,D):\\n\", confs[:5])\n",
        "print(\"\\nFirst 5 times (sec) (A,B,C,D):\\n\", times[:5])\n",
        "print(\"\\nFirst 5 correctness flags (A,B,C,D):\\n\", oks[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNGXYKOpi0r5",
        "outputId": "2c68a6ce-95de-4984-8bc2-762cb5df5310"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 confidences (A,B,C,D):\n",
            " [[0.22229803 0.2532501  0.11593659 0.7026045 ]\n",
            " [0.22229803 0.2532501  0.11593659 0.7026045 ]\n",
            " [0.22229803 0.2532501  0.11593659 0.7026045 ]\n",
            " [0.22229803 0.2532501  0.11593659 0.7026045 ]\n",
            " [0.8048309  0.4974504  0.9526833  0.877165  ]]\n",
            "\n",
            "First 5 times (sec) (A,B,C,D):\n",
            " [[1.392876   0.0063738  0.1137031  0.02299892]\n",
            " [0.0049773  0.00786057 0.00701183 0.02092551]\n",
            " [0.00403045 0.0080063  0.00741818 0.01948753]\n",
            " [0.00507551 0.00809344 0.00792632 0.01992278]\n",
            " [0.00437528 0.0077288  0.00675506 0.01818722]]\n",
            "\n",
            "First 5 correctness flags (A,B,C,D):\n",
            " [[False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9: Quick summary statistics\n",
        "import pandas as pd\n",
        "# Compute per-model averages\n",
        "avg_conf = confs.mean(axis=0)\n",
        "std_conf = confs.std(axis=0)\n",
        "avg_time = times.mean(axis=0)\n",
        "std_time = times.std(axis=0)\n",
        "acc      = oks.mean(axis=0)\n",
        "# Assemble into DataFrame\n",
        "summary = pd.DataFrame({\n",
        "    'Avg Confidence': avg_conf,\n",
        "    'Std Confidence': std_conf,\n",
        "    'Avg Time (s)'  : avg_time,\n",
        "    'Std Time (s)'  : std_time,\n",
        "    'Accuracy'      : acc\n",
        "}, index=['ResNet18','ResNet34','ResNet50','ResNet152'])\n",
        "\n",
        "print(\"Summary statistics by model:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APxx6s38j3C-",
        "outputId": "cfa2f583-f606-4c87-8163-7fde8f656d2b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary statistics by model:\n",
            "           Avg Confidence  Std Confidence  Avg Time (s)  Std Time (s)  \\\n",
            "ResNet18         0.727814        0.273904      0.004681      0.013954   \n",
            "ResNet34         0.775295        0.253715      0.006958      0.001803   \n",
            "ResNet50         0.799098        0.244461      0.007820      0.002676   \n",
            "ResNet152        0.840349        0.216998      0.021013      0.006444   \n",
            "\n",
            "           Accuracy  \n",
            "ResNet18     0.7244  \n",
            "ResNet34     0.7508  \n",
            "ResNet50     0.7716  \n",
            "ResNet152    0.8016  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: convert arrays to CSV files for easier inspection:\n",
        "import pandas as pd\n",
        "# Create DataFrames\n",
        "idxs = np.arange(N)\n",
        "cols = ['ResNet18','ResNet34','ResNet50','ResNet152']\n",
        "df_confs = pd.DataFrame(confs, index=idxs, columns=cols)\n",
        "df_times = pd.DataFrame(times, index=idxs, columns=cols)\n",
        "df_oks   = pd.DataFrame(oks.astype(int), index=idxs, columns=cols)\n",
        "\n",
        "# Save to CSV\n",
        "df_confs.to_csv('confs.csv', index_label='sample')\n",
        "df_times.to_csv('times.csv', index_label='sample')\n",
        "df_oks.to_csv('oks.csv',   index_label='sample')\n",
        "\n",
        "print(\"Saved CSVs: confs.csv, times.csv, oks.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QJBjChHj-Wa",
        "outputId": "ea0c7ccb-9aa1-45c8-814d-65b586281b0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CSVs: confs.csv, times.csv, oks.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CSVs in Colab (uncomment to use)\n",
        "# files.download('confs.csv')\n",
        "# files.download('times.csv')\n",
        "# files.download('oks.csv')"
      ],
      "metadata": {
        "id": "tT8h8LS4kEM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
